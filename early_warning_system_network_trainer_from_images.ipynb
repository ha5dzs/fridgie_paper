{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gzTeFXi-fL0"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT:\n",
        "# First of all, copy the 'use_this_in_the_tensorflow_code.zip' file into this environment.\n",
        "# You have to do this every time you are running this in Colab, because it discards everything after you close it.\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "\n",
        "try:\n",
        "  # Open the file\n",
        "  the_zip_file = zipfile.ZipFile('./use_this_in_the_tensorflow_code.zip', 'r')\n",
        "  # Extract the contents to the same directory as this code is running in.\n",
        "  the_zip_file.extractall('./')\n",
        "  # Close the file\n",
        "  the_zip_file.close()\n",
        "except:\n",
        "  print(\"The zip file could not be opened. Make sure you upload it to the same directory where this code is.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we define our directories. All manual, for clarity.\n",
        "\n",
        "# Training data set\n",
        "\n",
        "training_source_path = './fridgie_data_training'\n",
        "\n",
        "# Check a condition\n",
        "train_dir_check_airflow = os.path.join(training_source_path + '/check_airflow')\n",
        "\n",
        "try:\n",
        "  print(f\"There are {len(os.listdir(train_dir_check_airflow))} images in the training data check_airflow.\")\n",
        "except:\n",
        "  print(\"Looks like the training data wasn't extracted properly.\")\n",
        "\n",
        "# Testing data set\n",
        "\n",
        "testing_source_path = './fridgie_data_testing'\n",
        "\n",
        "test_dir_high_heatload = os.path.join(testing_source_path + '/high_heatload')\n",
        "\n",
        "try:\n",
        "  print(f\"There are {len(os.listdir(test_dir_high_heatload))} images in the testing data high_heatload.\")\n",
        "except:\n",
        "  print(\"Looks like the testing data wasn't extracted properly.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG_0xUOZCs8e",
        "outputId": "22384b0c-d86c-424c-8233-f29d9bd505e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10000 images in the training data check_airflow.\n",
            "There are 2500 images in the testing data high_heatload.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual machine learing thing: the neural network we have\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# This is the model definition\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Since our images are 5-by-1 pixels, this can be fairly simple.\n",
        "    tf.keras.layers.Flatten(), # Input layer. This is not really a layer, but it strips extra dimensions from the data\n",
        "    tf.keras.layers.Dense(94, activation = tf.nn.relu), # Hidden layer\n",
        "    tf.keras.layers.Dense(6, activation = tf.nn.softmax) # Output layer, must match the number of labels\n",
        "])\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'rmsprop',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "-L9MsWCcGZS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we are reducing the temperature and duty cycle measurements as image data, we will use the image data generator.\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "no_of_batches = 32\n",
        "\n",
        "train_gen = ImageDataGenerator( rescale = 1.0/255. ) # Image data is encoded as 8-bit values.\n",
        "\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "    training_source_path,\n",
        "    batch_size = no_of_batches\n",
        ")\n",
        "\n",
        "test_gen = ImageDataGenerator( rescale = 1.0/255. ) # Same as above\n",
        "\n",
        "test_generator = test_gen.flow_from_directory(\n",
        "    testing_source_path,\n",
        "    batch_size = no_of_batches\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKp70a1cLRSw",
        "outputId": "96349de7-fd47-42e9-9094-ccc89b2a51e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 60000 images belonging to 6 classes.\n",
            "Found 15000 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since training can be a long thing, it is worthwhile to do a callback function\n",
        "# This stops training when we reached the required accuracy when training and validating the data\n",
        "# Also, training for too long may have a negative effect on performance\n",
        "\n",
        "class are_we_there_yet(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # We can separate the training and validation accuracy.\n",
        "    required_training_accuracy = 0.99\n",
        "    required_validation_accuracy = 0.99\n",
        "    # This runs at every epoch's end, and checks whether we can stop.\n",
        "    if(logs.get('accuracy') >= required_training_accuracy and logs.get('val_accuracy') >= required_validation_accuracy):\n",
        "      print(\"\\n\\nWe got it, stopping training.\\n\\n\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "RXFG_BKjShqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we do the training\n",
        "\n",
        "no_of_epochs = 50 # This is way too many, the callback function will stop training when we are done.\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = no_of_epochs,\n",
        "    verbose = 1,\n",
        "    validation_data = test_generator,\n",
        "    callbacks = [are_we_there_yet()]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egyVwRpGNxK0",
        "outputId": "1253cf8b-c798-4d88-c8b5-84b15a78ecf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 112s 59ms/step - loss: 4.6720 - accuracy: 0.9096 - val_loss: 1.2648 - val_accuracy: 0.9216\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 105s 56ms/step - loss: 0.4529 - accuracy: 0.9769 - val_loss: 0.0579 - val_accuracy: 0.9898\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.2537 - accuracy: 0.9832 - val_loss: 0.0561 - val_accuracy: 0.9923\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.1980 - accuracy: 0.9847 - val_loss: 0.0472 - val_accuracy: 0.9907\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 102s 55ms/step - loss: 0.1474 - accuracy: 0.9869 - val_loss: 0.0287 - val_accuracy: 0.9953\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.1332 - accuracy: 0.9873 - val_loss: 0.0712 - val_accuracy: 0.9902\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.1297 - accuracy: 0.9879 - val_loss: 0.0291 - val_accuracy: 0.9948\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.1361 - accuracy: 0.9880 - val_loss: 0.0298 - val_accuracy: 0.9950\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.1231 - accuracy: 0.9886 - val_loss: 0.0807 - val_accuracy: 0.9907\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.1359 - accuracy: 0.9890 - val_loss: 0.2830 - val_accuracy: 0.9756\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.1264 - accuracy: 0.9893 - val_loss: 0.0686 - val_accuracy: 0.9925\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.1127 - accuracy: 0.9888 - val_loss: 0.0240 - val_accuracy: 0.9963\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.1035 - accuracy: 0.9898 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.1057 - accuracy: 0.9898 - val_loss: 0.0298 - val_accuracy: 0.9955\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9903\n",
            "\n",
            "We got it, stopping training.\n",
            "\n",
            "\n",
            "1875/1875 [==============================] - 98s 53ms/step - loss: 0.0904 - accuracy: 0.9903 - val_loss: 0.0585 - val_accuracy: 0.9923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "\n",
        "model.save_weights('./saved_model') # Save the file in the same working directory.\n",
        "\n",
        "# ...and at this point, you can process the model further, as you wish.\n",
        "\n"
      ],
      "metadata": {
        "id": "jv47KXl4KsQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}